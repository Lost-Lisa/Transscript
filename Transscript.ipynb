{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcript Audio Editor(TAE)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import io\n",
    "from google.cloud import speech\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file('G:\\\\My Drive\\\\CLG_Project\\\\PYtimestampKey\\\\api-key.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIM / Objective of your project\n",
    "# To reduce time in audio editing process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#important Imports from google.cloud import speech\n",
    "\n",
    "# save1\n",
    "# save2\n",
    "# save3\n",
    "# save4\n",
    "\n",
    "def transcribe_file_with_word_time_offsets(speech_file,language):\n",
    "\n",
    "    print(\"Start\")\n",
    "    print(\"checking credentials\")\n",
    "      \n",
    "    client = speech.SpeechClient(credentials=credentials)\n",
    "    \n",
    "    print(\"Checked\")\n",
    "    with io.open(speech_file, 'rb') as audio_file:\n",
    "        content = audio_file.read()\n",
    "              \n",
    "    print(\"audio file read\")    \n",
    "    \n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "    \n",
    "    print(\"config start\")\n",
    "    config = speech.RecognitionConfig(\n",
    "            encoding=speech.RecognitionConfig.AudioEncoding.FLAC,\n",
    "            language_code=language,\n",
    "            enable_word_time_offsets=True)\n",
    "    \n",
    "#     print (config)\n",
    "    \n",
    "    \n",
    "    print(\"Recognizing:\")\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "    print(\"Recognized\")\n",
    "    #debug_options\n",
    "#     print(\"response\",response)\n",
    "#     print('response result',response.results)\n",
    "    word_dict = {}\n",
    "    \n",
    "    for result in response.results:\n",
    "        alternative = result.alternatives[0]\n",
    "        \n",
    "        print(\"Transcript: {}\".format(alternative.transcript))\n",
    "        tran_script = alternative.transcript.split()\n",
    "        print(\"Confidence: {}\".format(alternative.confidence))\n",
    "#         print(\"alternative\",alternative)\n",
    "        for word_info in alternative.words:\n",
    "#             print(\"alternative.words\",alternative.words)\n",
    "#             print(\"word_info\",word_info)\n",
    "            word = word_info.word\n",
    "            \n",
    "            start_time = word_info.start_time\n",
    "            end_time = word_info.end_time\n",
    "            word_dict[word] = [start_time.total_seconds(), end_time.total_seconds()]\n",
    "\n",
    "            print(f\"Word: {word}, start_time: {start_time.total_seconds()}, end_time: {end_time.total_seconds()}\")\n",
    "#     print(word_dict)\n",
    "#     print(word_dict['is'][0], word_dict['is'][1] )\n",
    "    return (word_dict,tran_script)        \n",
    "            \n",
    "def find_start_time(word,word_dict):\n",
    "    \n",
    "    return (word_dict[word][0])\n",
    "\n",
    "def find_end_time(word,word_dict):\n",
    "    \n",
    "    return (word_dict[word][1])                \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# recorded audio is now processed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "checking credentials\n",
      "Checked\n",
      "audio file read\n",
      "config start\n",
      "Recognizing:\n",
      "Recognized\n",
      "Transcript: welcome to Amity University Kolkata\n",
      "Confidence: 0.9825577735900879\n",
      "Word: welcome, start_time: 0.6, end_time: 1.2\n",
      "Word: to, start_time: 1.2, end_time: 1.4\n",
      "Word: Amity, start_time: 1.4, end_time: 2.1\n",
      "Word: University, start_time: 2.1, end_time: 2.6\n",
      "Word: Kolkata, start_time: 2.6, end_time: 3.5\n",
      "['welcome', 'to', 'Amity', 'University', 'Kolkata']\n"
     ]
    }
   ],
   "source": [
    "audio_name = 'avi3'\n",
    "\n",
    "path = 'G:\\\\My Drive\\\\CLG_Project\\\\recordings_lossless\\\\'+audio_name+'.flac'\n",
    "lang = \"en-US\"\n",
    "word_dict,tran_script = transcribe_file_with_word_time_offsets(path,lang)\n",
    "# word = 'Kolkata'\n",
    "print(tran_script)\n",
    "# print(find_start_time(word,word_dict))\n",
    "# print(find_end_time(word,word_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the Difference in new script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "welcome to Amity Kolkata\n",
      "University\n"
     ]
    }
   ],
   "source": [
    "def Diff(li1, li2):\n",
    "    li_dif = [i for i in li1 + li2 if i not in li1 or i not in li2]\n",
    "    return li_dif\n",
    "def find_diff(tran_script):\n",
    "#     script = \"my name is Avinash\"\n",
    "#     new_script = \"my name  Avinash\"\n",
    "    new_script = str(input())\n",
    "#     li1 = ['my', 'name', 'is', 'Avinash']\n",
    "    # tran_script\n",
    "    li2 = new_script.split()\n",
    "    li3 = Diff(tran_script, li2)\n",
    "    print(li3[0])\n",
    "    return li3[0]\n",
    "\n",
    "\n",
    "\n",
    "# print(cut_word)\n",
    "# find_start_time(cut_word,word_dict)\n",
    "\n",
    "\n",
    "cut_word = find_diff(tran_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avina\\anaconda3\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='G:\\\\My Drive\\\\CLG_Project\\\\trimmer_test_audio\\\\trimmedavi31.wav'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "wave_audio = 'avi31'\n",
    "path1 = 'G:\\\\My Drive\\\\CLG_Project\\\\trimmer_test_audio\\\\'+wave_audio+'.wav'\n",
    "make = AudioSegment.from_wav(path1)\n",
    "# pydub does things in milliseconds\n",
    "#ten_seconds = 10 * 1000\n",
    "\n",
    "# first_10_seconds = make[:cut_start]+make[cut_end:]\n",
    "# if len(cut_word)>1:\n",
    "#     for word in cut_word:\n",
    "#         cut_start = find_start_time(word,word_dict)\n",
    "#         cut_end = find_end_time(word,word_dict)\n",
    "#         make[:cut_start]+make[cut_end:]\n",
    "        \n",
    "#         print(cut_start,cut_end)\n",
    "# #         print(words)\n",
    "# elif len(cut_word)==1:\n",
    "#     cut_start = find_start_time(cut_word,word_dict)\n",
    "#     cut_end = find_end_time(cut_word,word_dict)\n",
    "cut_start = find_start_time(cut_word,word_dict)\n",
    "cut_start -=0.1\n",
    "cut_end = find_end_time(cut_word,word_dict)\n",
    "cut_end+=0.2\n",
    "# print(cut_start)\n",
    "\n",
    "first_10_seconds = make[:cut_start*1000]+make[cut_end*1000:]\n",
    "\n",
    "\n",
    "# last_5_seconds = song[26*1000:]\n",
    "#backwards = song.reverse()\n",
    "new_audio = first_10_seconds\n",
    "\n",
    "\n",
    "new_wave_audio = 'trimmed'+wave_audio\n",
    "path2 = 'G:\\\\My Drive\\\\CLG_Project\\\\trimmer_test_audio\\\\'+new_wave_audio+'.wav'\n",
    "new_audio.export(path2, format='wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3\n"
     ]
    }
   ],
   "source": [
    "# if len(cut_word)>1:\n",
    "#     for word in cut_word:\n",
    "#         cut_start = find_start_time(word,word_dict)\n",
    "#         cut_end = find_end_time(word,word_dict)\n",
    "#         print(cut_start,cut_end)\n",
    "# #         print(words)\n",
    "# else:\n",
    "cut_start = find_start_time(cut_word,word_dict)\n",
    "cut_end = find_end_time(cut_word,word_dict)\n",
    "print(cut_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########NOT IN USE#######################\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description=__doc__,\n",
    "        formatter_class=argparse.RawDescriptionHelpFormatter)\n",
    "    parser.add_argument(dest='path', help='File or GCS path for audio file to be recognized')\n",
    "    parser.add_argument(\"-s\",\"--string\", type=str, required=True)\n",
    "    args = parser.parse_args()\n",
    "    if args.path.startswith('gs://'):\n",
    "        transcribe_gcs_with_word_time_offsets(args.path,args.string)\n",
    "    else:\n",
    "        transcribe_file_with_word_time_offsets(args.path,args.string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['welcome', 'to', 'Amity', 'University', 'Kolkata']\n"
     ]
    }
   ],
   "source": [
    "print(tran_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "wave_audio = 'avinash'\n",
    "path1 = 'G:\\\\My Drive\\\\CLG_Project\\\\trimmer_test_audio\\\\'+wave_audio+'.wav'\n",
    "# path1 = 'G:\\\\My Drive\\\\CLG_Project\\\\trimmer_test_audio\\\\audio1.wav'\n",
    "make = AudioSegment.from_wav(path1)\n",
    "# pydub does things in milliseconds\n",
    "#ten_seconds = 10 * 1000\n",
    "\n",
    "# first_10_seconds = make[:cut_start]+make[cut_end:]\n",
    "if len(cut_word)>1:\n",
    "    difference = 0\n",
    "    for word in cut_word:\n",
    "        cut_start = find_start_time(word,word_dict)\n",
    "        cut_start -= difference\n",
    "        cut_end = find_end_time(word,word_dict)\n",
    "        cut_end -= difference\n",
    "        differnce = cut_end - cut_start\n",
    "        first_10_seconds = make[:cut_start*1000]+make[cut_end*1000:]\n",
    "        \n",
    "        print(cut_start,cut_end)\n",
    "#         print(words)\n",
    "elif len(cut_word)==1:\n",
    "    cut_start = find_start_time(cut_word,word_dict)\n",
    "    cut_end = find_end_time(cut_word,word_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# last_5_seconds = song[26*1000:]\n",
    "#backwards = song.reverse()\n",
    "new_audio = first_10_seconds\n",
    "\n",
    "\n",
    "new_wave_audio = 'trimmed'+wave_audio\n",
    "path2 = 'G:\\\\My Drive\\\\CLG_Project\\\\trimmer_test_audio\\\\'+new_wave_audio+'.wav'\n",
    "new_audio.export(path2, format='wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
